{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c00934d-0f14-4c1a-a563-94d627b377e5",
   "metadata": {},
   "source": [
    "## Notebook to visualize a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15dfdc1-5054-40bc-9631-4c7426eecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_imports import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mattport.nerf.dataset.image_dataset import ImageDataset, collate_batch\n",
    "from mattport.nerf.dataset.collate import CollateIterDataset, collate_batch_size_one\n",
    "from mattport.nerf.dataset.utils import get_dataset_inputs_dict\n",
    "from mattport.nerf.field_modules.ray_generator import RayGenerator\n",
    "from mattport.structures.rays import RayBundle\n",
    "from mattport.utils.io import get_absolute_path\n",
    "from mattport.viewer.plotly import get_line_segments_from_lines\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import open_dict\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bdf3b-60a0-4bb2-9f88-ae36f2036c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../configs\"):\n",
    "    cfg = compose(config_name=\"default.yaml\")\n",
    "    cfg.dataset.downscale_factor = 4\n",
    "    \n",
    "cfg.dataset.data_directory = get_absolute_path(cfg.dataset.data_directory)\n",
    "dataset_inputs = get_dataset_inputs(**cfg.dataset)[\"train\"]\n",
    "image_dataset = ImageDataset(\n",
    "            image_filenames=dataset_inputs.image_filenames, downscale_factor=dataset_inputs.downscale_factor\n",
    "        )\n",
    "iter_dataset = CollateIterDataset(\n",
    "    image_dataset,\n",
    "    collate_fn=lambda batch_list: collate_batch(\n",
    "        batch_list, cfg.dataloader.num_rays_per_batch, keep_full_image=True\n",
    "    ),\n",
    "    num_samples_to_collate=cfg.dataloader.num_images_to_sample_from,\n",
    "    num_times_to_repeat=cfg.dataloader.num_times_to_repeat_images,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    iter_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=cfg.dataloader.num_workers,\n",
    "    collate_fn=collate_batch_size_one,\n",
    "    pin_memory=True,\n",
    ")\n",
    "dataloader_iter = iter(dataloader)\n",
    "\n",
    "ray_generator = RayGenerator(dataset_inputs.intrinsics, dataset_inputs.camera_to_world)\n",
    "\n",
    "num_batches = 10\n",
    "for _ in tqdm(range(num_batches)):\n",
    "    batch = next(dataloader_iter)\n",
    "    ray_bundle = ray_generator.forward(batch[\"indices\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b85061-a1b0-458b-9d00-96cde6f37dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_image(image_dataset.get_image(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f4a78-4b8b-4615-a127-7d7579874765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    # set the color of the sampled rays\n",
    "    c, y, x = [i.flatten() for i in torch.split(batch[\"local_indices\"], 1, dim=-1)]\n",
    "    batch[\"image\"][c,y,x] = 1.0\n",
    "\n",
    "    # batch[\"image\"] is num_images, h, w, 3\n",
    "    images = torch.split(batch[\"image\"], 1, dim=0)\n",
    "    image_list = [image[0] for image in images]\n",
    "    image = torch.cat(image_list, dim=1) # cat along the width dimension\n",
    "\n",
    "    # the white pixels are rays\n",
    "    media.show_image((image*255).to(torch.uint8))\n",
    "\n",
    "def sample_and_show_batch():\n",
    "    batch = next(iter(dataloader))\n",
    "    show_batch(batch)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e625f7-fa1f-4b3f-acd4-bddfcdf7cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sample_and_show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cf48a-823e-4395-99ca-eda4c2026440",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_indices = batch[\"indices\"]\n",
    "ray_bundle = ray_generator(ray_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646107c0-f979-408a-941f-98b2ad3e07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 1\n",
    "size = 8\n",
    "data = []\n",
    "data += [go.Scatter3d(\n",
    "    x=ray_generator.camera_to_world[::skip,0,3],\n",
    "    y=ray_generator.camera_to_world[::skip,1,3],\n",
    "    z=ray_generator.camera_to_world[::skip,2,3],\n",
    "    mode='markers',\n",
    "    name=\"origins\",\n",
    "    marker=dict(color='rgba(0, 0, 0, 1)', size=size)\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ba9bd-2902-4c46-b592-bc87ac8c71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_plane = 1.0\n",
    "far_plane = 6.0\n",
    "lines = torch.stack([ray_bundle.origins + ray_bundle.directions * near_plane,\n",
    "                     ray_bundle.origins + ray_bundle.directions * far_plane\n",
    "                    ], dim=1).tolist() # (num_rays, 2, 3)\n",
    "lines = torch.tensor(random.sample(lines, k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991df6a2-efe3-4412-ba41-9a244e2e90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data += get_line_segments_from_lines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2404d8-ca9e-4630-9f67-7c68d19458cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    margin=go.layout.Margin(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=100,\n",
    "        t=100,\n",
    "        pad=4\n",
    "    ),\n",
    "    scene=go.layout.Scene(\n",
    "        aspectmode=\"data\",\n",
    "        camera=dict(\n",
    "            up=dict(x=0, y=0, z=1),\n",
    "            center=dict(x=0, y=0, z=0),\n",
    "            eye=dict(x=1.25, y=1.25, z=1.25)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa506fe-66a1-4284-ade4-8c90fde5476a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259edb0-4126-4930-99f4-b5574dbb2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"temp.png\")\n",
    "plotly_image = imageio.imread(\"temp.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a11772-4692-4800-b446-cfdbe4ab92fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f5370-3b0f-4ad1-87a1-df479ae85b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mattport",
   "language": "python",
   "name": "mattport"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
